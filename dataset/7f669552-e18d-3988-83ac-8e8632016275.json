{"paragraphs": ["Introduction", "Ever play an online game and feel your blood pressure rise over complete frustration with poor sportsmanship, or even worse felt your anxiety spike due to harassment and bullying taking place right before your eyes?", "A game is only as strong as the community that supports it, but what happens when a few bad apples disrupt the flow and prevent others from having fun? Most gamers have a story where they\u2019ve experienced griefing or team-killing, or even worse had another player verbally insult them in a way that goes well beyond \u201ctrash talk.\u201d In fact, a recent study by anti-bullying organization Ditch the Label reported that 57 percent of the young people it surveyed experienced bullying online while playing games; even more alarming was 22 percent said it caused them to stop playing. Instead of drawing people to games, are more people turning away from them due to these unpleasant social interactions?", "Negative experiences playing games online aren\u2019t anything new; you can go back to the earlier days of commercial MMORPGs, such as EverQuest and Ultima Online, and find plenty of examples of these scenarios. A common perception among gamers has been it just comes with the territory if you want to play online, but that doesn\u2019t make it okay. Playing games should bring people together, and as gamers, we all know how powerful these experiences can be. Nobody should have to tolerate hate speech or threats to their safety to simply engage with their hobby online.", "This issue has only continued to heat up as more games are evolving and becoming online-centric. The extra emphasis on their social aspects has forced developers to get creative to help encourage players to \u201cplay nice.\u201d With more initiatives and efforts in this area, we chatted with leaders across the industry, from developers figuring out solutions to companies that specialize in moderation, to gain insight into the ever-growing and complex issue.", "Riot has experimented with many different design tactics to address disruptions in League of Legends", "It's About Disruption", "It\u2019s About Disruption", "The word \u201ctoxic\u201d seems to go hand-in-hand with online gaming and has been used as a way to describe problematic, negative players who go out of their way to make the experience unpleasant for others. Maybe it\u2019s a player who\u2019s purposely throwing a match in Dota 2, or spamming insults in League of Legends\u2019 chat to make someone feel bad about their skills. This is what many developers consider \u201cdisruptive behavior\u201d and is the preferred term when discussing these types of individuals.", "No matter the phrasing, it still all comes down to one thing: They are getting in the way of how the game is meant to be experienced. Every developer we spoke to for this feature commented on this specifically and why it\u2019s a bummer. \u201cIt\u2019s in everyone\u2019s best interest to make playing their games a fun, happy experience because that\u2019s why people go to play these games \u2013 they want to have a fun time,\u201d says Overwatch principal designer Scott Mercer.", "This also extends to keeping players invested in a gaming experience. If something doesn\u2019t feel fun or pleasant, why stick around? Dave McCarthy, head of operations at Xbox, puts forth a simple comparison to illustrate how important it is that these digital landscapes feel safe and protected: \u201cI just think it\u2019s as simple as, \u2018Would you walk into a physical space, anywhere where you face harassment, or are made to feel unwelcome by certain imagery or language that\u2019s used there?\u2019 No, of course you wouldn\u2019t; you get out of that space physically. And the same is true for the digital space.\u201d", "Overwatch", "When players log into games, they look for the social norms to get an idea of what\u2019s acceptable. Is it a more laid back, jokey atmosphere? Is it composed of serious competitors wanting to get down to business? That\u2019s why it\u2019s extremely important the tone is set early in games and services. Chris Priebe, founder and CEO of Two Hat Security, a company that provides moderation tools, says that a community\u2019s identity forms on day one and that\u2019s why it\u2019s so important for those behind the games to build and inform the culture. \u201cWhen people launch a game, they need to be thinking about, \u2018How am I building the community and putting people in the community?\u2019 I think too often in the game industry it\u2019s just, \u2018Launch it and the culture will form itself.\u2019\u201d", "Priebe discussed how oftentimes moderation and chat features are thought about far too late in development, without much consideration going into how to shape the community. He compared it to hosting a party and how it takes shape once you set the tone. \u201cIf you don\u2019t set a tone, it can go very, very poorly,\u201d Priebe says. \u201cThat\u2019s why people have bouncers at the front door. Somehow with games, we don\u2019t think we need to put bouncers at the front door, and we wonder why things go so terribly wrong.\u201d", "While this might seem discouraging, in more recent years. Priebe says he has seen an increased effort going into changing this. People across the industry are working hard to find answers, whether that\u2019s more transparent guidelines, better moderation tools, or designing solutions within the game. However, it all comes with time and experience, using the community as a testing ground.", "Blizzard most recently introduced role queue to help bypass team composition disputes in Overwatch", "The Fair Play Alliance\u2019s Mission As developers seek solutions, it\u2019s become apparent that collaboration is going to be a huge tool moving forward. Here\u2019s where The Fair Play Alliance, a global coalition of game companies, plans to \u201cunlock the best possible online experiences for players everywhere.\u201d Over 120 companies are represented with a great mix of key players around the industry, such as Blizzard, Mixer, Roblox, and Epic Games. \u201cThe [Fair Play] Alliance is about driving lasting change for game design\u201d says co-founder Carlos Figueiredo, who also is the director of community safety and trust at Two Hat Security. With an eye toward making games more \u201cpositive and productive experiences,\u201d The Fair Play Alliance is in place to detect problems before they snowball. \u201cSomething people can miss is the way you design your game can be conducive to the experience,\u201d Figueiredo says. \u201cThe environment in the game can influence negative behavior. This is at the very top mind of the Alliance \u2026 if you really think about game design and how it can be used to facilitate and foster those positive interactions.\u201d The goal is to better understand the needs of players and how to ensure online games are a positive experience for everyone.\u201d For more information, visit fairplayalliance.org.", "The Learning Process", "The Learning Process", "The more people we spoke to about this topic, the more it was clear how complicated and difficult of an issue it is. Most companies are experimenting with different features or tools to see what works, and some are even still deciding where to draw the line between \u201cokay\u201d and \u201cnot okay.\u201d \u201cIt turns out that calling something toxic is difficult to design for,\u201d says Weszt Hart, head of player dynamics at Riot Games. \u201cIt\u2019s difficult to make decisions on, because it\u2019s so subjective. What\u2019s toxic to you might not be toxic to somebody else. Trash talk could be for some people considered toxic, but for others, that\u2019s just what we do with our friends.\u201d", "Working on League of Legends, a team-based game that earned quite a reputation for its toxic community, Hart says it was challenging for the team to figure out where to focus to mitigate these issues. To figure out what the community considered \u201cgood\u201d and \u201cbad,\u201d Riot presented the now-defunct Tribunal, where players logged in and reviewed cases, deciding if an offender should be disciplined or pardoned. After this, Riot tried encouraging more positive interactions by rolling out the honor system, a way to give your teammate kudos if you thought they did a good job. \u201cBut then we realized that all of those systems were after-the-fact, they were all after the games,\u201d Hart explains. \u201cThey weren\u2019t helping to avoid potential transgressions. We needed to identify where the problems were actually happening, maybe even before games.\u201d", "Rainbow Six Seige", "Enter team builder. \u201cTeam builder was looking at addressing, I suppose a way to put it is, a shortcoming of our design,\u201d Hart says. \u201cBecause as the community evolved, the concept of a meta evolved with it. Players started telling us how to play and the system wasn\u2019t recognizing their intent, so in an effort to play the way they wanted to play, they were essentially yelling out in chat the role that they wanted. We needed to find a way to help the system, help players play the way they wanted.\u201d Riot created team builder for matches to start out on a better note, as a way to decrease players entering matches already frustrated, which often just increased the chance of negative interactions.", "While Riot isn\u2019t the first to deal with players treating each other poorly, the influence of its systems can be seen around the industry. Take Blizzard\u2019s cooperative shooter Overwatch, for example. Overwatch launched back in 2016, and while being considered one of the more positive communities, it dealt with its share of problem players, which game director Jeff Kaplan often had to address in his developer update videos. Kaplan finally put it bluntly: \u201cOur highest-level philosophy is, if you are a bad person doing bad things in Overwatch, we don\u2019t want you in Overwatch.\u201d", "Since launch, Overwatch has received several improvements to the game: better reporting tools, an endorsement system encouraging positivity, and most recently, role queue, which took away the extra frustration and bickering that often erupted over team composition. The latter two are very reminiscent of League\u2019s honor system and team builder.", "Overwatch is far from Blizzard\u2019s first foray into the world of online gaming, so the team anticipated some issues, but it also charted new territory. \u201cI don\u2019t think we were expecting exactly the sort of behavior that happened after launch,\u201d says senior producer Andrew Boyd. \u201cI know that there were a lot of new things for us to deal with. I think this is one of the first games where we\u2019re really dealing with voice as an integrated part of the game, and that changed the landscape a lot. That said, when we saw it, obviously, addressing those issues became very important to us very quickly, and we started to take steps to make the game a better place for folks.\u201d", "While developers can try to catch potential issues ahead of time, most of the time they really don\u2019t expose themselves until the game is up and running. Ubisoft Montreal experienced this first-hand with Rainbow Six Siege, forcing the company to crack down on bad behavior and get creative with its solutions. A player behavior team was created to \u201cfocus on promoting the behaviors we hope to see in the game,\u201d says community developer Karen Lee. It\u2019s here that the team worked on Reverse Friendly Fire (RFF) system to help with team-killing. \u201cRFF was first concepted to help contain the impact of players abusing the game\u2019s friendly fire mechanic,\u201d Lee says.", "Rainbow Six Siege\u2019s developer updates openly discuss toxicity and the solutions going forward", "RFF makes it so if you attempt to harm an ally, the damage reverses straight back to you. Since then, Ubisoft has iterated on it to ensure it works on all the different operators and their gadgets. Now, before any new operators go live, the player-behavior team reviews it, trying to determine all the ways they could be used unintentionally by the community to cause griefing. \u201cWe also have weekly and monthly reports that go out to the entire team,\u201d Lee explains. \u201cThese help everyone gauge the health of the community, and we highlight the top concerns from the week.\u201d", "Many different game companies and organizations have been coming together [see The Fair Play Alliance sidebar] to share ideas and work toward change. Even though developers have learned much of what works and what doesn\u2019t, there isn\u2019t a one-size-fits-all solution, as all games are different, whether it\u2019s the audience or genre. \u201cThe problem space is too big to look at any particular feature, and say, \u2018This is how you do it,\u2019\u201d Hart says. \u201cThere aren\u2019t best practices yet for what we\u2019re calling player dynamics, which is the field of design for player-to-player interactions and motivations. Depending on your game and your genre, some things may work better than others.\u201d", "EA community team senior director Adam Tanielian speaks at the Building Healthy Communities Summit at this year\u2019s EA Play", "Streaming, Gaming, And Mixer\u2019s Example Mixer has become a big force in the streaming world, which was only amplified by a partnership with Tyler \u201cNinja\u201d Blevins, who has now amassed over 1 million followers on the platform. Gaming and streaming are so intertwined that it\u2019s a big part of how people discover games nowadays. That means the needs of moderation are only increasing in these areas both for streamers and their viewers. Mixer came onto the scene back in 2016 when it was called Beam, and it has taken a stance against toxicity and vowed to improve tools to help combat it. The entire tone of Mixer has been much more friendly and inviting than its competitors. General manager Chad Gibson thinks it comes down to Mixer\u2019s focus on community from day one and thinking about ways to foster it. \u201cIf there was one thing that\u2019s probably had the most profound impact, it\u2019s been transparency and consistency,\u201d he says. This means making the rules of what\u2019s acceptable as clear as possible and constantly striving to improve upon that. Mixer just recently launched a new system called Toxicity Screen, which allows streamers to determine the words and type of communication that is allowed in their chat. Streamers can also fine-tune it to be more restrictive to new members and loosen it for longtime viewers they\u2019ve built a trust with. \u201cIt\u2019s important for us to give the streamers the ability and the tools to foster the type of growth they want,\u201d Gibson explains. Gibson thinks Mixer openly speaking out against toxicity has only helped it achieve the community it wants to foster. \u201cWe want it to be really clear what is allowed on the platform, and the more we can be consistent about this, the better our streamers can help push their community in that direction as well.\u201d", "Putting The Power In The Community", "Putting The Power In The Community", "Building healthier communities doesn\u2019t just fall on the developers and publishers. Sure, designing different mechanics and improving moderation tools are steps in the right direction, but they also need the community\u2019s help to be successful. It makes sense. The people that play your game make it what it is and know it the best. That\u2019s why more and more developers and companies are depending on their communities to give feedback and self-moderate by reporting bad player behavior. \u201cEveryone needs to be involved,\u201d Priebe says. \u201cThe gamers need to say, \u2018Look, I\u2019m sick of this.\u2019\u201d Priebe was quick to point out that he thinks most gamers already feel this way but feels more need to put their foot down and be vocal to help shift the culture. \u201cIt will take some gamers to say, \u2018No, that isn\u2019t cool. You can\u2019t be in our guild unless you have good sportsmanship,\u2019\u201d he says.", "Many believe the community should be just as involved with the process as they are when giving feedback on games for betas. \u201cWe need to work with our players and say, \u2018What do you guys think?\u2019 The same way we do when we develop our games,\u201d says EA community team senior director Adam Tanielian. \u201cWe think the same idea should apply to our communities. How do we keep them healthy? And how do we build tools?\u201d EA recently held a summit devoted to building healthier communities to start getting feedback from gamers and devs alike. Born from this was a \u201cplayer council,\u201d which Tanielian says meets regularly and is similar to the ones they have for their various franchises, but this focuses on feedback for tools, policies, and how EA should categorize toxicity. \u201cWe know that we have to take action,\u201d Tanielian says. \u201cWe can\u2019t just talk about it and not do something. Some things take longer than others, but there are always things we can be doing. There are always areas that we can be addressing.\u201d", "Most platforms have parental settings, like the Xbox One (pictured here), to give parents some control over their child\u2019s online experience", "Many people we chatted with discussed how easy-to-use reporting tools have been essential, but players need to be encouraged to use them. If they\u2019re hard to find, require players to visit a website, or are needlessly complex, developers and moderators simply won\u2019t get the valuable information they need. Reporting also helps developers learn what the community values. \u201cThe community itself is sort of driving what\u2019s good and what\u2019s not great for it in terms of communication, in terms of that play experience,\u201d Mercer says. \u201cI think the most important thing about the reporting is it\u2019s a way for the community to help police itself, to help determine amongst itself what they find acceptable or not.\u201d", "Players often feel more encouraged to report if they know it\u2019s facilitating change. Sure, giving players the ability to mute or block players that rub them the wrong way helps, but once the Overwatch team started following up on reports and letting the players know action was taken, they noticed it led to an increase in reporting. \u201cThat was important, reaching out and building that trust,\u201d Mercer says. \u201cSaying, \u2018Hey, as a member of the Overwatch community, you are part of the solution to dealing with issues of players acting poorly within a game.\u2019\u201d", "Xbox allows players to search for others with similar goals so they can team up in games", "While self-moderation has certainly been key to helping get problem players out of games, Microsoft saw an opportunity to take it one step further. For those who just want to play or converse with like-minded individuals, Microsoft created the \u201cclubs\u201d feature (online meeting spaces) on Xbox One, where people with similar values, interests, and goals can come together. McCarthy says Microsoft has seen great success in this area. \u201cWe discovered the strong communities are not only ones where you provide kind of a safe space and a set of norms, but they\u2019re also the ones where they get some degree of self-governance,\u201d he explains.", "Microsoft has also used clubs as a testing ground for new moderation features, which McCarthy says are in the works. A long-term goal for Xbox is to give you more choices and tools in how you play. \u201cWhat I mean is put the dials and sliders ultimately in your hands so that you could decide, \u2018Hey, I want to filter out stuff that is detected as harassing-type messages,\u2019 or I\u2019ll be silly, like, \u2018I want to filter out the word \u2018peanut butter\u2019 and never see the word peanut butter again.\u2019 You could customize down to whatever level you felt was appropriate as a user.\u201d", "Involving the community and putting moderation tools in their hands is a step in the right direction, and it\u2019s encouraging to see more companies put forth ways for the community to help. After all, this is too big of an issue to be tackled alone, and it will only grow in complexity as games continue to get bigger and are turning more and more into social activities.", "Building A Better Future", "Building A Better Future", "The industry doesn\u2019t get better if it\u2019s not constantly finding new solutions, and many companies are realizing that more needs to be done as our technology grows. \u201cThis needs to be a solved problem,\u201d Priebe says. \u201cBecause games are [becoming] more and more voice-driven, especially as you need collaboration more than ever. People are realizing that if you have social games, that\u2019s where your friends are.\u201d", "While game developers are still behind in this area, there is plenty of hope for the future. \u201cWhat we are facing in gaming is more of a cultural shift over the last 10 years ... and it is on us to react more quickly than we have in the past to stay ahead of the curve,\u201d says Rainbow Six Siege community developer Craig Robinson. \u201cRight now, we are playing catch-up, and that\u2019s not where we need to be in order to get toxicity under control. I expect for there to be a ton of improvements over the next 5-10 years across the industry, especially with the various publishers and developers sharing their learnings and insights through the Fair Play Alliance.\u201d", "Minecraft, the best-selling game of all time, is available across 20 different platforms, making community moderators and parental controls essential", "And plenty of people tackling this issue have already been thinking ahead. Right now, we\u2019ve depended largely on reactive measures to moderate people. The problem with that is it\u2019s after the fact, as in the damage is already done. Many have an eye toward being more proactive, which means trying to anticipate problems before they happen, whether that\u2019s designing to combat them or depending more on filters and A.I. \u201cI think one of the biggest challenges is being stuck in the ways we\u2019ve done things before,\u201d Hart says. \u201cWe have the social needs increasing for players online; we need to think of our games differently. We need to be much more proactive. If we wait to have a game to be thinking about how people may interact with each other within that game, we\u2019re already behind because then we have to retrofit systems onto an existing game as opposed to proactively designing to reduce disruption and to help produce those successful interactions. A short way of putting it is we need to move from punitive to proactive.\u201d", "What\u2019s encouraging is that technology is only going to get better, and many feel optimistic that A.I. will be a great asset in moderation going forward. \u201cA.I. is something that could really be a difference-maker with regards to how we\u2019re able to moderate and how we\u2019re able to enforce its scale across the community,\u201d Tanielian says. Companies like Microsoft have already been investing in this area by trying to get as much data as possible to ensure the A.I. is accurate. \u201cThere\u2019s actually goodness in those models getting trained more and more by more data,\u201d McCarthy says. \u201cAs an example, we\u2019ve done something called \u2018photo DNA\u2019 at Microsoft, where we tag certain images and we actually share that database with a large range of other companies. This is where I think collaboration is actually really important in the industry. Because if we can start to share some of these models and learning, then they get more sophisticated and accurate, and they actually can help a larger range of users overall. That\u2019s just something we have to keep chipping away at: How do we utilize powerful technology like that in the right way? And to get it trained broadly across the industry to do the things we want it to do?\u201d", "These are big questions, but they\u2019re the ones we can\u2019t afford to leave unsolved, as we\u2019re spending more and more time in these online spaces.", "This article originally appeared in the November 2019 issue of Game Informer."], "publicationId": "7abf5426-5048-31ce-9c0a-822c58b19b47", "authors": ["Features Editor", "Kimberley Is Usually Playing The Latest Rpg", "Sports Title", "Or Narrative-Driven Experience. She Has Also Amassed More Than Two Hundred Stanley Cups While Playing As The Blackhawks In Various Nhl Games."], "title": "Building Stronger Communities", "id": "7f669552-e18d-3988-83ac-8e8632016275", "keywords": ["players", "community", "online", "stronger", "game", "thats", "team", "building", "communities", "help", "games", "way", "play"], "summary": "Negative experiences playing games online aren\u2019t anything new; you can go back to the earlier days of commercial MMORPGs, such as EverQuest and Ultima Online, and find plenty of examples of these scenarios.\nA common perception among gamers has been it just comes with the territory if you want to play online, but that doesn\u2019t make it okay.\nThat\u2019s why more and more developers and companies are depending on their communities to give feedback and self-moderate by reporting bad player behavior.\nAnd how do we build tools?\u201d EA recently held a summit devoted to building healthier communities to start getting feedback from gamers and devs alike.\n\u201cWe have the social needs increasing for players online; we need to think of our games differently.", "pubDate": null, "url": "https://www.gameinformer.com/feature/2019/11/18/building-stronger-communities"}