{"id": "2dfc4567-60fc-3353-9c1d-0b34583d983c", "title": "Watch a Robot Dog Learn How to Deftly Fend Off a Human", "url": "https://www.wired.com/story/watch-a-robot-dog-learn-how-to-deftly-fend-off-a-human#intcid=_wired-most-popular-right-rail_ac06f781-6321-48b3-86ae-bd5957936ae7_popular4-1", "summary": "And now, behold: The makers of the Jueying robot dog have taught it a fascinating way to fend off a human antagonizer who kicks it over or pushes it with a stick.\nLi and his colleagues started by training the software that would guide a virtual version of the robot dog.\nIf the virtual robot tried something that got it closer to the goal, it got a digital reward.\nAfter many of such guided attempts of trial and error, the simulated robot would become an expert in a skill.\nFor example, the robot can start in a different pose, such as lying down on the ground, standing, falling over, and so on.\u201d", "paragraphs": ["Study hard enough, kids, and maybe one day you\u2019ll grow up to be a professional robot fighter. A few years ago, Boston Dynamics set the standard for the field by having people wielding hockey sticks try to keep Spot the quadrupedal robot from opening a door. Previously, in 2015, the far-out federal research agency Darpa hosted a challenge in which it forced clumsy humanoid robots to embarrass themselves on an obstacle course way outside the machines\u2019 league. (I once asked you, dear readers, to stop laughing at them, but have since changed my mind.) And now, behold: The makers of the Jueying robot dog have taught it a fascinating way to fend off a human antagonizer who kicks it over or pushes it with a stick.", "A team of researchers from China\u2019s Zhejiang University\u2014where the Jueying\u2019s hardware was also developed\u2014and the University of Edinburgh didn\u2019t teach the Jueying how to recover after an assault, so much as they let the robot figure it out. It\u2019s a dramatic departure from how a hardware developer like Boston Dynamics goes about teaching a robot how to move, using decades of human experience to hard code, line by line, the way a robot is supposed to react to stimuli like, um, a person\u2019s foot.", "Video: Yang et al., Sci Robot. 5, eabb2174 (2020)", "But there\u2019s got to be a better way. Imagine, if you will, a soccer team. Midfielders, strikers, and a goalkeeper all do generally soccer-esque things like running and kicking, but each position has its own specialized skills that make it unique. The goalkeeper, for instance, is the only person on the field who can grab the ball with their hands without getting yelled at.", "In traditional methods of training robots, you\u2019d have to meticulously code all of those specialized behaviors. For instance, how should the actuators\u2014motors that move a robot\u2019s limbs\u2014coordinate to make the machine run like a midfielder? \u201cThe reality is that if you want to send a robot into the wild to do a wide range of different tasks and missions, you need different skills, right?\u201d says University of Edinburgh roboticist Zhibin Li, corresponding author on a recent paper in the journal Science Robotics describing the system.", "Li and his colleagues started by training the software that would guide a virtual version of the robot dog. They developed a learning architecture with eight algorithmic \"experts\" that would help the dog produce complex behaviors. For each of these, a deep neural network was used to train the computer model of the robot to achieve a particular skill, like trotting or righting itself if it fell on its back. If the virtual robot tried something that got it closer to the goal, it got a digital reward. If it did something non-ideal, it got a digital demerit. This is known as reinforcement learning. After many of such guided attempts of trial and error, the simulated robot would become an expert in a skill.", "Video: Yang et al., Sci Robot. 5, eabb2174 (2020)", "Compare this to the traditional line-by-line way of coding a robot to do something as seemingly simple as climbing stairs\u2014this actuator turns this much, this other actuator turns this much. \u201cThe AI approach is very different in the sense that it captures experience, which the robot has tried hundreds of thousands of times, or even millions of times,\u201d says Li. \u201cSo in the simulated environment, I can create all possible scenarios. I can create different environments or different configurations. For example, the robot can start in a different pose, such as lying down on the ground, standing, falling over, and so on.\u201d"], "authors": ["Matt Simon", "Matt Simo"], "keywords": ["virtual", "watch", "turns", "university", "robot", "way", "robots", "different", "fend", "deftly", "learn", "tried", "dog", "yang", "human"], "pubDate": null, "publicationId": "212e56a6-e535-3569-ad1b-2215526c1d9d"}